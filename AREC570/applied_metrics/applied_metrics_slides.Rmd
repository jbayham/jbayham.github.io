---
title: "AREC 570: Applied Econometrics"
author: "Jude Bayham"
date: "October 30, 2019"
output:
  ioslides_presentation: 
    css: ../styles.css
    logo: ../CSU-Ram-357.png
    widescreen: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```


## Intro

Within reduced-form approach, more attention to credible causal estimates

Gold Standard: Randomization of the treatment 

Techniques to recreate experimental ideal using observational data

  - Difference in differences
  - Regression discontinuity design
  - Matching methods


## Surrogate Variables

A surrogate in this case is an intermediate variable 

Surrogate condition is that outcome and treatment are independent conditional on surrogate and controls 

Ex: Website change (treatment) and user engagement (outcome); surrogate is webpage visits

Estimate the relation between surrogate and outcome, then use the result to impute missing outcome in experimental sample

Alternatively, estimate the relation between the treatment and surrogate, then use it to impute missing treatment indicator in observation sample

## Supplementary Analysis

Support the credibility of the primary analysis (not finding better estimates or select competing models)

Involves creative strategies to "question" the identification strategy

Placebo analysis: replace the outcome of interest with an outcome that should not be affected by treatment

  - Ex: Effect of winning the lottery on earnings.  Treatment randomly assigned?  
  - Swap pre-lottery earnings for post-lottery earnings (statistically insignificant effect; power?)
  - In RDD, other covariates shouldn't break across discontinuity; otherwise, confound treatment effect estimate
  

## Robustness and Sensitivity

Leamer criticism of econometric practice of running many models and cherry picking significant results (p-hacking)

Often present several combinations of controls or specifications to demonstrate the robustness of the estimate

Athey-Imbens approach to sample-splitting:

  - Assume model: $E[Y_i|X_i,Z_i]=\beta_0+\beta_W W + \beta_z^{\prime} Z_i$
  - split sample based on each covariate $X_i \in {0,1}$, estimate regression using each subset 
  - calculate $\tilde{\beta}_W = \bar{X} \hat{\beta}_{W1} + (1-\bar{X}) \hat{\beta}_{W0}$
  - repeat for all $i$ and report standard deviation of $\tilde{\beta}_W$
  
## Machine Learning Methods

Generally designed for a different problem: prediction rather than causal inference (counterfactual prediction)

Related concepts: externaly valid causal inference should produce prediction

Prediction can be agnostic to causal relationship

Trade lower variance for bias

Data driven model selection

## Unsupervised vs. Supervised Learning

Unsupervised methods find patterns, group, or reduce dimensionality

  - Clustering: K-means, partitioning
  
Supervised methods focus on "out-of-sample" prediction - divide into *training* and *testing* sets

  - Classification and Regression Trees (CART) and Random Forest
  - Penalized regression: LASSO
  - Boosting https://www.stata-journal.com/sjpdf.html?articlenum=st0087
  
## Using ML for Causal Inference

Two-step LASSO

  1. Estimate LASSO on outcome to find variables correlated with outcome
  2. Estiamte LASSO on treatment to find variables correlated with treatment
  3. Estimate regression with union

## Using ML for Causal Inference CATE

Conditional Average Treatment Effects (CATE) - treatment effect heterogeneity

  - Causal trees: modified CART focused on minimizing MSE of treatment effect rather than outcome 
  
## Using ML for Causal Inference IV

Instrumental Variables

  - First stage of IV is often focused on prediction
  - Use ML methods to find "good" subset or combination of instruments
  - Weak instruments can be a significant and overlooked problem

## Summary

Supplementary Analysis

  - Credibility tests for identification strategy
  - Robustness and sensitivity
  
Machine Learning

  - Focused on prediction
  - Methods emerging to study causal relationships using ML tools



# Tackling False Positives

## Motivation

Many studies based on an arbitrarily chosen $\alpha=.05$ (null ritual)

Less attention is paid to the power (Type 2 error)

Large sample size implies low prob of Type 2 and bias toward Type 1

Big data hubris: Often feel confident with large datasets, but many issues can exist and be amplified (sampling error, selection, measurement error)

Propose a toolbox rather than focus on p-value --> move away from "statistical rituals"

## The case against p-value 

p-value measures how unlikely the observed statistic is if $H_0$ were true

does not measure prob that $H_0$ is true nor the importance of the variable being tested

Figure 1 shows that the p-val $\Pr(F>3|H_0)=.01$ [gray shade] but $\Pr(F<3|H_1)=.0001$ [red shade]

So, odds are even lower that measured F is compatible with $H_1$ (0.0001) than with $H_0$ (0.01)

We should be concerned with relative probabilities

## Zero-probability paradox

The hypothesis test is set up to test whether the coefficient is *exactly* 0.  This is rarely our literal null hypothesis

We can get significance with a "large enough N"

Even when $H_0$ is practically true, we can "reject" with large enough sample size (Type 1 error false positive increases)

p-value cannot balance the influence of sample size against model explanatory power

## Toolbox

"Judgmenet is part of the art of statistics"

Bayes Factor: looks at the relative likelihood of observing the data given $H_1$ versus $H_0$.  Balancing the T1 and T2 errors

Prob that $H_0$ is true: relevant for testing economic significance

Adaptive significance: $\alpha$ should decrease with sample size

Optimal leve of significance: allows flexibility given the context and researchers priors

Equal probability test: back out the sample size needed to balance T1 and T2 errors

## More on large sample bias

mispecification introduces bias

more data can amplify model mispecification because the model is a simplification of the underlying process

more units or time may introduce different data generating processes that aren't well-described in a single model

# Simulation

## Overview

Simulation to illustrate empirical results and explore counterfactuals

Simulation as a method of analysis

  - economic models
  
  - integrated economic-??? models
  
Simulation to elicit data

## Simulation to illustrate results

Use simulation to illustrate outcomes under a counterfactual 

Example: Future Fire Costs 

Explore model implications by simulating fire cost under housing growth scenarios

https://sites.google.com/site/judebayham/home


## Simulation as a method

Simulation is a technique used to demonstrate how a model behaves and to predict counterfactual outcomes. 

The objective is to simulate reality then explore a counterfactual – what happens if we change this policy

Recognize that the model builder is acting like an engineer that constructs the outcome.  The outcome isn’t a mystery but it might be counterintuitive.

The challenge is to communicate the mechanisms and levers in the model that drive certain outcomes.


## Models

Macroeconomic GE models

Computable General Equilibrium (also dynamic versions)

Integrated models

  - Bioeconomic – infectious disease, fisheries, wildfire
  
  - Economic-Engineering - water

Agent-based models

## Constructing a simulation model

Define the structure of the model (similar to theory)

  - Who are the agents making decisions?
  
  - How do they interact?
  
  – What is exogenous (the parameters of the model)?  
  
  - What is endogenous (variables solved within model)?
  
Derive equilibrium conditions – supply=demand, Euler equation

Maybe derive estimable equations

## Solving a simulation model sometimes called the inverse problem

Assume parameters and run

Calibration (inverse problem)

  - Calibrate (or train) model parameters using observed data on endogenous variables (or model outcomes).

  - Example: Given a model structure based on economic and epidemiological theory and data on prevalence rates over time, one can calibrate parameters representing the infectivity or infection probability per unit of time

  - Run counterfactual scenarios

## Simulation to elicit data

Let people play in a simulation to understand how decisions are made

Video game economics

## Conclusions

Broad class of model

Powerful tool for understanding complex relationships

Transparency is critical especially in complex models (assumptions, levers or drivers)


# Qualitative and Mixed Methods

## Motivation

Qualitative methods generall not considered part of the economists toolkit (2-4 semesters on econometrics)

Generally considered too subjective - economists don't trust people

Qualitative methods have their strengths and may complement quantitative methods

## Differences

Open-ended vs. closed-ended questions

Closed-ended questions are structured from the beginning

  - reponse set is finite; respondents choose

Open-ended questions are less structured

Researcher can learn and adapt to discussion

The goal is to recover the full picture of factors and processes at work in the respondent's thinking.

## Where qualitative methods excel

1. when very little is known about a topic

2. when quant research already exists but questions still remain

3. when iteration between interviewer and interviewee is necessary to elicit information

4. when topic is sufficiently complex

5. when researchers own views are of interest

## Types of qual methods

1. In-depth interviews

2. Focus groups

3. Case studies or on site visits

4. Fieldwork ethnography

5. Life histories

6. Mixed Methods

## More on mixed methods

Combine qual and quant methods

1. qual $\rightarrow$ quant: exploratory analysis when little is known; then develop structured data elicitation or collect secondary data

2.  quant $\rightarrow$ qual: first administer large-scale survey; then follow with in-depth interviews

3. qual and quant simulateneously: use qual work to understand institutional setting that produced the data

## Examples

Bewley/Blinder studies on why firms didn't cut wages during slack labor market conditions.  Inability to distinguish between competing theories.  Fairness and morale - not homo-economicus

Contingent valuation: issues include 

  1. don't necessarily think through all of the tradeoffs
  
  2. don't trust revenue collected will be used as stated
  
  3. object to putting prices on things beyond value
  
  4. warm glow of helping the environment
  
The recommended solutions involve mixed methods approach starting with focus groups or interviews

## Concerns

Problem: Too much room for subjectivity

Solution: document procedures, comment on unique features, research in teams, cross-check findings

Problem: deliberate misrepresentation by respondents to influence some outcome;  may not understand or be able to articulate why or how decisions are made (Friedman's billiards player) 

Solution: train interviewers to remain objective and 


# Writing Empirical Methods


## Overview

The objective is to clearly communicate the why and how you conducted the analysis

Identification strategy

Sufficient detail for reproduction - some of it may belong in an appendix

  - Derivation of new estimators, computational techniques
  
Organization is important for clarity

Audience determines level of detail

## Intro

Start with an overview of the section

Communicate the estimation strategy



## Example 1

Estimation of the model follows a two-step procedure related to
that in Berry, Levinsohn, and Pakes (1995). A rigorous
presentation of the estimation procedure is included in a
technical appendix that follows Bayer, McMillan, and Rueben
(2005), including a discussion of methods for simplifying the
computation and a description of the asymptotic properties of the
estimator. In this section, we outline the estimation procedure,
focusing on the identification of the model.

## Example 2

Our objective is to determine the factors that
drive suppression resource allocation decisions
across multiple fires. We use the Arellano-
Bond (AB) systems estimator (Arellano
and Bover 1995; Blundell and Bond 1998) to
estimate daily resource allocation equations
(equation [10]). This dynamic panel estimator
is appropriate for our analysis because
wildfire suppression is an inherently dynamic
process and several factors that influence suppression
resource dispatch are endogenous.
The AB model leverages the dynamic panel
structure of the data to identify internal instruments
for endogenous regressors.

## Example 3 Simulation

We will illustrate the fundamental importance of conflict costs by simulating the model under three distinct scenarios: 

  1.	A single group that chooses base location and subsequent hunting effort,

  2.	Two amicable groups that both choose base location and subsequent hunting effort without fear of conflict with each other,

  3.	Two rival groups that both face the cost of conflict when choosing base location and subsequent hunting effort.  

We choose to compare the simulation results under these three scenarios for two reasons.  First, they demonstrate that the presence of multiple groups in a region is not a sufficient condition for the existence of buffer zones.  Second, the scenarios follow the evolution of human expansion across a region.  Scenario 1 represents ...  Scenario 2 represents ...  While scenario 3 represents ...

## Example 4 Interdisciplinary; Regression and Simulation

General science puts most methods in appendix with a small section at the end

  - general description of the methods in the introduction

Explain the parts but also how they fit together

Disease avoidance


## Identification strategy

Explain the source of variation driving the result

What are you controlling for and why

## Speficy the model

Use familiar notation when possible: letters for variables and symbols for parameters

Use matrix notation when possible

## Inference

Remind the reader of your hypotheses and how your empirical strategy tests them

How are you computing standard errors or constructing your tests

<!-- ## Sample image include -->

```{r eval=FALSE, include=FALSE}
#knitr::include_graphics("figures/dir_structure.png")
```


<!-- ## Tools for data management and analysis -->
<!-- | Software | Learning  | Scope | Community  | Cost | -->
<!-- |----------|-----------|-------|------------|------| -->
<!-- | [R](https://en.wikipedia.org/wiki/R_(programming_language))        | moderate  | extensive | large | free | -->
<!-- | [Python](https://en.wikipedia.org/wiki/Python_(programming_language))   | moderate* | extensive | large | free | -->
<!-- | [Stata](https://en.wikipedia.org/wiki/Stata)    | easy      | conventional data | econ | high | -->
<!-- | [Matlab](https://en.wikipedia.org/wiki/MATLAB)   | moderate  | extensive | moderate* | high | -->

