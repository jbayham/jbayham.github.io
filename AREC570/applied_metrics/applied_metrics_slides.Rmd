---
title: "AREC 570: Applied Econometrics"
author: "Jude Bayham"
date: "October 30, 2019"
output:
  ioslides_presentation: 
    css: ../styles.css
    logo: ../CSU-Ram-357.png
    widescreen: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```


## Intro

Within reduced-form approach, more attention to credible causal estimates

Gold Standard: Randomization of the treatment 

Techniques to recreate experimental ideal using observational data

  - Difference in differences
  - Regression discontinuity design
  - Matching methods


## Surrogate Variables

A surrogate in this case is an intermediate variable 

Surrogate condition is that outcome and treatment are independent conditional on surrogate and controls 

Ex: Website change (treatment) and user engagement (outcome); surrogate is webpage visits

Estimate the relation between surrogate and outcome, then use the result to impute missing outcome in experimental sample

Alternatively, estimate the relation between the treatment and surrogate, then use it to impute missing treatment indicator in observation sample

## Supplementary Analysis

Support the credibility of the primary analysis (not finding better estimates or select competing models)

Involves creative strategies to "question" the identification strategy

Placebo analysis: replace the outcome of interest with an outcome that should not be affected by treatment

  - Ex: Effect of winning the lottery on earnings.  Treatment randomly assigned?  
  - Swap pre-lottery earnings for post-lottery earnings (statistically insignificant effect; power?)
  - In RDD, other covariates shouldn't break across discontinuity; otherwise, confound treatment effect estimate
  

## Robustness and Sensitivity

Leamer criticism of econometric practice of running many models and cherry picking significant results (p-hacking)

Often present several combinations of controls or specifications to demonstrate the robustness of the estimate

Athey-Imbens approach to sample-splitting:

  - Assume model: $E[Y_i|X_i,Z_i]=\beta_0+\beta_W W + \beta_z^{\prime} Z_i$
  - split sample based on each covariate $X_i \in {0,1}$, estimate regression using each subset 
  - calculate $\tilde{\beta}_W = \bar{X} \hat{\beta}_{W1} + (1-\bar{X}) \hat{\beta}_{W0}$
  - repeat for all $i$ and report standard deviation of $\tilde{\beta}_W$
  
## Machine Learning Methods

Generally designed for a different problem: prediction rather than causal inference (counterfactual prediction)

Related concepts: externaly valid causal inference should produce prediction

Prediction can be agnostic to causal relationship

Trade lower variance for bias

Data driven model selection

## Unsupervised vs. Supervised Learning

Unsupervised methods find patterns, group, or reduce dimensionality

  - Clustering: K-means, partitioning
  
Supervised methods focus on "out-of-sample" prediction - divide into *training* and *testing* sets

  - Classification and Regression Trees (CART) and Random Forest
  - Penalized regression: LASSO
  - Boosting https://www.stata-journal.com/sjpdf.html?articlenum=st0087
  
## Using ML for Causal Inference

Two-step LASSO

  1. Estimate LASSO on outcome to find variables correlated with outcome
  2. Estiamte LASSO on treatment to find variables correlated with treatment
  3. Estimate regression with union

## Using ML for Causal Inference CATE

Conditional Average Treatment Effects (CATE) - treatment effect heterogeneity

  - Causal trees: modified CART focused on minimizing MSE of treatment effect rather than outcome 
  
## Using ML for Causal Inference IV

Instrumental Variables

  - First stage of IV is often focused on prediction
  - Use ML methods to find "good" subset or combination of instruments
  - Weak instruments can be a significant and overlooked problem

## Summary

Supplementary Analysis

  - Credibility tests for identification strategy
  - Robustness and sensitivity
  
Machine Learning

  - Focused on prediction
  - Methods emerging to study causal relationships using ML tools



# Tackling False Positives

## Motivation

Many studies based on an arbitrarily chosen $\alpha=.05$ (null ritual)

Less attention is paid to the power (Type 2 error)

Large sample size implies low prob of Type 2 and bias toward Type 1

Big data hubris: Often feel confident with large datasets, but many issues can exist and be amplified (sampling error, selection, measurement error)

Propose a toolbox rather than focus on p-value --> move away from "statistical rituals"

## The case against p-value 

p-value measures how unlikely the observed statistic is if $H_0$ were true

does not measure prob that $H_0$ is true nor the importance of the variable being tested

Figure 1 shows that the p-val $\Pr(F>3|H_0)=.01$ [gray shade] but $\Pr(F<3|H_1)=.0001$ [red shade]

So, odds are even lower that measured F is compatible with $H_1$ (0.0001) than with $H_0$ (0.01)

We should be concerned with relative probabilities

## Zero-probability paradox

The hypothesis test is set up to test whether the coefficient is *exactly* 0.  This is rarely our literal null hypothesis

We can get significance with a "large enough N"

Even when $H_0$ is practically true, we can "reject" with large enough sample size (Type 1 error false positive increases)

p-value cannot balance the influence of sample size against model explanatory power

## Toolbox

"Judgmenet is part of the art of statistics"

Bayes Factor: looks at the relative likelihood of observing the data given $H_1$ versus $H_0$.  Balancing the T1 and T2 errors

Prob that $H_0$ is true: relevant for testing economic significance

Adaptive significance: $\alpha$ should decrease with sample size

Optimal leve of significance: allows flexibility given the context and researchers priors

Equal probability test: back out the sample size needed to balance T1 and T2 errors

## More on large sample bias

mispecification introduces bias

more data can amplify model mispecification because the model is a simplification of the underlying process

more units or time may introduce different data generating processes that aren't well-described in a single model



<!-- ## Sample image include -->

```{r eval=FALSE, include=FALSE}
#knitr::include_graphics("figures/dir_structure.png")
```


<!-- ## Tools for data management and analysis -->
<!-- | Software | Learning  | Scope | Community  | Cost | -->
<!-- |----------|-----------|-------|------------|------| -->
<!-- | [R](https://en.wikipedia.org/wiki/R_(programming_language))        | moderate  | extensive | large | free | -->
<!-- | [Python](https://en.wikipedia.org/wiki/Python_(programming_language))   | moderate* | extensive | large | free | -->
<!-- | [Stata](https://en.wikipedia.org/wiki/Stata)    | easy      | conventional data | econ | high | -->
<!-- | [Matlab](https://en.wikipedia.org/wiki/MATLAB)   | moderate  | extensive | moderate* | high | -->

